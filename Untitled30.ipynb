{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFU8CEgRdkKwhWSdQhNZ1a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deimiser/DV/blob/main/Untitled30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def map_function(text):\n",
        "    return Counter(text.split())\n",
        "\n",
        "def reduce_function(counters):\n",
        "    return sum(counters, Counter())\n",
        "\n",
        "def map_reduce(data, map_func, reduce_func, num_processes=2):\n",
        "    with Pool(num_processes) as pool:\n",
        "        return reduce_func(pool.map(map_func, data))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_data = [\n",
        "        \"Hello world\",\n",
        "        \"World of MapReduce\",\n",
        "        \"MapReduce example\",\n",
        "        \"Word Count in MapReduce\"\n",
        "    ]\n",
        "\n",
        "    # Word Count\n",
        "    result = map_reduce(input_data, map_function, reduce_function)\n",
        "\n",
        "    # Display Word Count result\n",
        "    print(\"Word Count Result:\")\n",
        "    for word, count in result.items():\n",
        "        print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOYSUNsEp12K",
        "outputId": "fb7d104b-b665-483c-ff0f-c9047380c596"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Count Result:\n",
            "Hello: 1\n",
            "world: 1\n",
            "World: 1\n",
            "of: 1\n",
            "MapReduce: 3\n",
            "example: 1\n",
            "Word: 1\n",
            "Count: 1\n",
            "in: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BloomFilter:\n",
        "    def __init__(self, size, hash_functions):\n",
        "        self.bit_array = [0] * size\n",
        "        self.size = size\n",
        "        self.hash_functions = [lambda item, i=i: hash(f\"{item}{i}\") % size for i in range(hash_functions)]\n",
        "\n",
        "    def add(self, item):\n",
        "        for hash_function in self.hash_functions:\n",
        "            self.bit_array[hash_function(item)] = 1\n",
        "\n",
        "    def __contains__(self, item):\n",
        "        return all(self.bit_array[hash_function(item)] == 1 for hash_function in self.hash_functions)\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    bloom_filter = BloomFilter(1000, 3)\n",
        "    elements_to_add = [\"apple\", \"banana\", \"cherry\", \"dog\", \"elephant\"]\n",
        "    [bloom_filter.add(element) for element in elements_to_add]\n",
        "\n",
        "    elements_to_check = [\"apple\", \"banana\", \"grape\", \"elephant\", \"cat\"]\n",
        "    [print(f\"{element} {'may be in the set.' if element in bloom_filter else 'is definitely not in the set.'}\") for element in elements_to_check]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFBk_x7urffr",
        "outputId": "7fd65a40-2c56-4e26-864c-0caea8003631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple may be in the set.\n",
            "banana may be in the set.\n",
            "grape is definitely not in the set.\n",
            "elephant may be in the set.\n",
            "cat is definitely not in the set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def generate_candidates(prev_candidates, k):\n",
        "    return set(frozenset(itemset1.union(itemset2)) for itemset1 in prev_candidates for itemset2 in prev_candidates if len(itemset1.union(itemset2)) == k)\n",
        "\n",
        "def prune_candidates(candidates, prev_frequent_sets):\n",
        "    return {c for c in candidates if all(subset in prev_frequent_sets for subset in combinations(c, len(c)))}\n",
        "\n",
        "def apriori(transactions, min_support):\n",
        "    itemsets = [set(transaction) for transaction in transactions]\n",
        "    k, frequent_sets = 1, []\n",
        "\n",
        "    while True:\n",
        "        candidates = prune_candidates(generate_candidates(frequent_sets, k), frequent_sets)\n",
        "        counts = {c: 0 for c in candidates}\n",
        "\n",
        "        for itemset in itemsets:\n",
        "            for candidate in candidates:\n",
        "                if candidate.issubset(itemset):\n",
        "                    counts[candidate] += 1\n",
        "\n",
        "        frequent_sets_k = {itemset for itemset, count in counts.items() if count >= min_support}\n",
        "\n",
        "        if not frequent_sets_k:\n",
        "            break\n",
        "\n",
        "        frequent_sets.extend(frequent_sets_k)\n",
        "        k += 1\n",
        "\n",
        "    return frequent_sets\n",
        "\n",
        "# Example usage:\n",
        "transactions = [\n",
        "    [\"bread\", \"milk\", \"eggs\"],\n",
        "    [\"bread\", \"butter\", \"eggs\"],\n",
        "    [\"milk\", \"butter\", \"eggs\"],\n",
        "    [\"bread\", \"milk\", \"butter\", \"eggs\"]\n",
        "]\n",
        "\n",
        "min_support = 2\n",
        "result = apriori(transactions, min_support)\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "for itemset in result:\n",
        "    print(itemset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu5mh_Rtr_L1",
        "outputId": "d91f30f2-d31b-489b-b21d-bddf07085a47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def pagerank(graph, damping=0.85, epsilon=1e-8, max_iter=100):\n",
        "    n = len(graph)\n",
        "    A = np.array([[1 / len(graph.get(j, [])) if j in graph[i] else 0 for j in range(n)] for i in range(n)])\n",
        "    r = np.ones(n) / n\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        new_r = (1 - damping) / n + damping * A.T @ r\n",
        "\n",
        "        # Check for convergence\n",
        "        if np.linalg.norm(new_r - r, 2) < epsilon:\n",
        "            break\n",
        "\n",
        "        r = new_r\n",
        "\n",
        "    return r\n",
        "\n",
        "# Example graph: {node: [neighbors]}\n",
        "graph = {0: [1, 2], 1: [2], 2: [0, 3], 3: [2]}\n",
        "\n",
        "# Calculate PageRank scores\n",
        "scores = pagerank(graph)\n",
        "\n",
        "# Print PageRank scores\n",
        "for node, score in enumerate(scores):\n",
        "    print(f\"Node {node}: PageRank Score = {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlQuDeWLtN3A",
        "outputId": "7dd225fd-b764-4ebf-c32d-4ed02a353227"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node 0: PageRank Score = 0.1754\n",
            "Node 1: PageRank Score = 0.1866\n",
            "Node 2: PageRank Score = 0.3246\n",
            "Node 3: PageRank Score = 0.3134\n"
          ]
        }
      ]
    }
  ]
}